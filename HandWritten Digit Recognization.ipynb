{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN learns the filters automatically without mentioning it explicitly.\n",
    "# These filters help in extracting the right and relevant features from the input data\n",
    "# CNN also follows the concept of parameter sharing. \n",
    "# A single filter is applied across different parts of an input to produce a feature map\n",
    "# A Convolutional Neural Network is a powerful neural network that uses filters to extract features from images. \n",
    "# It also does so in such a way that position information of pixels is retaine\n",
    "# While solving an image classification problem using ANN, the number of trainable parameters increases drastically with an \n",
    "# increase in the size of the image. \n",
    "# Convolutional Neural Networks captures the spatial features from an image, which ANNs fail to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "# Dropout is an approach to regularization in neural networks which helps reducing interdependent learning amongst the neurons\n",
    "# A fully connected layer occupies most of the parameters, and hence, neurons develop co-dependency amongst each other during \n",
    "# training which curbs the individual power of each neuron leading to over-fitting of training data\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "# The simplest model is defined in the Sequential class which is a linear stack of Layers.\n",
    "# You can create a Sequential model and define all of the layers in the constructor\n",
    "\n",
    "# Model Inputs\n",
    "# The first layer in your model must specify the shape of the input.\n",
    "# This is the number of input attributes and is defined by the input_dim argument. This argument expects an integer.\n",
    "# For example, you can define input in terms of 8 inputs for a Dense type layer as follows:\n",
    "# Dense(16, input_dim=8)\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (60000, 28, 28, 1)\n",
      "train smaple 60000 \n",
      "test sample 10000\n"
     ]
    }
   ],
   "source": [
    "# CNN always have to feed a 4D array of shape (batch_size, height, width, depth)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
    "\n",
    "# define input data size \n",
    "input_size = (28,28,1)\n",
    "\n",
    "# convert the data into range from 0-1 \n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "print('x_train shape',x_train.shape)\n",
    "print('train smaple',x_train.shape[0],'\\ntest sample',x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create A model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "epochs = 10 \n",
    "\n",
    "# create a model object\n",
    "model = Sequential()\n",
    "\n",
    "# A filter (or kernel) is an integral component of the layered architecture. Generally, \n",
    "# it refers to an operator applied to the entirety of the image such that it transforms the information encoded in the pixels\n",
    "\n",
    "model.add(Conv2D(32, kernel_size =3,activation = 'relu',input_shape = input_size ))\n",
    "\n",
    "model.add(Conv2D(64,3,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train The model\n",
    "The model.fit() function of Keras will start the training of the model. It takes the training data, validation data, epochs, and batch size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 585s 10ms/sample - loss: 0.1576 - accuracy: 0.9524 - val_loss: 0.0515 - val_accuracy: 0.9828\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 611s 10ms/sample - loss: 0.0640 - accuracy: 0.9804 - val_loss: 0.0342 - val_accuracy: 0.9891\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 933s 16ms/sample - loss: 0.0457 - accuracy: 0.9862 - val_loss: 0.0316 - val_accuracy: 0.9905\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 805s 13ms/sample - loss: 0.0384 - accuracy: 0.9878 - val_loss: 0.0282 - val_accuracy: 0.9906\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 553s 9ms/sample - loss: 0.0298 - accuracy: 0.9900 - val_loss: 0.0285 - val_accuracy: 0.9904\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 682s 11ms/sample - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.0308 - val_accuracy: 0.9897\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 671s 11ms/sample - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.0309 - val_accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 696s 12ms/sample - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0286 - val_accuracy: 0.9917\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 622s 10ms/sample - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0311 - val_accuracy: 0.9917\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 687s 11ms/sample - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.0291 - val_accuracy: 0.9919\n",
      "model has successfully trained\n",
      "saving the model as mnist.h5\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size = 128, epochs = 10,validation_data=(x_test,y_test))\n",
    "# The model.fit() function of Keras will start the training of the model. \n",
    "# It takes the training data, validation data, epochs, and batch size.\n",
    "\n",
    "print('model has successfully trained')\n",
    "\n",
    "model.save('mnist.h5')\n",
    "# You mean a HDF5/H5 file, which is a file format to store structured data, its not a model by itself. \n",
    "# Keras saves models in this format as it can easily store the weights and model configuration in a single file\n",
    "\n",
    "print('saving the model as mnist.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tkinter import * \n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np\n",
    "model = load_model('mnist.h5')\n",
    "def predict_digit(img):\n",
    "    #resize image to 28x28 pixels\n",
    "    img = img.resize((28,28))\n",
    "    #convert rgb to grayscale\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    #reshaping to support our model input and normalizing\n",
    "    img = img.reshape(1,28,28,1)\n",
    "    img = img/255.0\n",
    "    #predicting the class\n",
    "    res = model.predict([img])[0]\n",
    "    return np.argmax(res), max(res)\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "        self.x = self.y = 0\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
    "        self.classify_btn = tk.Button(self, text = \"Recognise\", command =         self.classify_handwriting) \n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "    def classify_handwriting(self):\n",
    "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
    "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
    "        im = ImageGrab.grab(rect)\n",
    "        digit, acc = predict_digit(im)\n",
    "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r=8\n",
    "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
    "app = App()\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
